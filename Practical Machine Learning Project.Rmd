---
title: "Practical Machine Learning Project"
author: "Yong-Hao Bai"
date: "7/10/2020"
output: html_document
---

## Executive Summary

## load the required packages
```{r results='hide', message=FALSE}
library(caret); library(rattle); library(rpart); library(rpart.plot); library(randomForest); library(repmis);
library(lattice); library(ggplot2); library(readr); library(gbm)
```

## Load Data
```{r results='hide', message=FALSE}
set.seed(717)
trainurl = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testurl = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(trainurl, "pml-training.csv")
download.file(testurl, "pml-testing.csv")
training <- read.csv("pml-training.csv",  na.strings=c("NA","#DIV/0!", ""))
testing <- read.csv("pml-testing.csv",  na.strings=c("NA","#DIV/0!", ""))
#update datasets to exclude those variables with NA values
training <- training[, colSums(is.na(training)) == 0]
testing <- testing[, colSums(is.na(testing)) == 0]
```

#remove irrelevant variables to the prediction
```{r results='hide', message=FALSE}
newtraining <- training[,-c(1:7)]
newtesting <- testing[, -c(1:7)]
```

#For cross validation purpose, the training data will be split into training training and training testing. 
```{r echo=FALSE}
cv <- createDataPartition(y=newtraining$classe, p=0.7, list=FALSE)
training_train <- newtraining[cv, ] 
training_test <- newtraining[-cv, ]
```

###Decision Tree
```{r echo=FALSE}
modDT <- rpart(classe ~ ., data=training_train, method="class")
rpart.plot(modDT, main = "Classification Tree", extra=102, under=TRUE, faclen = 0, cex = .5)
```
```{r echo=FALSE}
predDT <- predict(modDT, training_test, type = "class")
accDT <- confusionMatrix(predDT, training_test$classe)
accDT
```


```{r echo=FALSE}
accDT$overall['Accuracy']
plot(accDT$table, col=Dtree$byClass, main=paste("Decision Tree - Accuracy =", round(accDT$overall['Accuracy'], 4)))
```
We see that the accuracy rate of the model is low: 0.7274,the out-of-sample-error is about 0.3 which is considerable.


### Classification tree
```{r echo=FALSE}
control <- trainControl(method = "cv", number = 5)

modRpart <- train(classe ~ ., data = training_train, method = "rpart", trControl = control)
print(modRpart, digits = 4)
```

```{r echo=FALSE}
fancyRpartPlot(modRpart$finalModel)
```

```{r echo=FALSE}
predRpart <- predict(modRpart, training_test)
accRpart <- confusionMatrix(training_test$classe, predict_rpart)
accRpart
```

```{r echo=FALSE}
accRpart$overall['Accuracy']
```

### Boosted Logistic Regression
```{r echo=FALSE}
modBLR <- train(classe ~ ., data = training_train, method = "LogitBoost", trControl = control)
predBLR <- predict(modBLR, training_test)
accBLR <- confusionMatrix(predBLR, training_test$classe)
print(modBLR)
```

```{r echo=FALSE}
accBLR$overall['Accuracy']
```

###Gradient Boosting
```{r echo=FALSE}
controlGBM <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
modGBM <- train(classe ~ ., data=training_train, method = "gbm", trControl = controlGBM, verbose = FALSE)
modGBM$finalModel
print(modGBM)
```

```{r echo=FALSE}
predGBM <- predict(modGBM, newdata=training_test)
accGBM <- confusionMatrix(predGBM, training_test$classe)
accGBM
```

```{r echo=FALSE}
accGBM$overall['Accuracy']
```

###Random Forest
```{r echo=FALSE}
modrf <- randomForest(classe ~., data = training_train, method = "class")
#rfmod <- train(classe ~., data = training_train, method="rf", trControl = control)
print(modrf, digits = 4)
```


```{r echo=FALSE}
predrf <- predict(modrf, training_test, type = "class")
accrf <- confusionMatrix(predrf, training_test$classe) 
accrf
```

```{r echo=FALSE}
accrf$overall['Accuracy']
```
Looking at the results, clearly, the random forest model provides a more accurate prediction of classe with 0.9955 compare to decision treeâ€™s 0.7488. The expected out-of-sample error is estimated at 0.005.

#Predictio on Testing
```{r echo=FALSE}
predict(modrf, newtesting)
```

#Variable Importance
```{r echo=FALSE}
varImp(modrf)
```

#plot of the model error rate by number of trees and 20 most important variables (out of 52)
```{r echo=FALSE}
plot(modrf, main="Random forest model error rate by number of trees")
```

```{r echo=FALSE}
accurary <- c(accDT$overall['Accuracy'], accRpart$overall['Accuracy'], accBLR$overall['Accuracy'], accGBM$overall['Accuracy'], accrf$overall['Accuracy'])
models <- c("Decision Tree", "CART", "Boosted Logistic Regression", "Gradient Boosting", "Random Forest")
x <- data.frame(Model = models, Accuracy = accurary)

ggplot(x, aes(x = Model, y = Accuracy)) + 
  geom_bar(stat = "identity", aes(fill = Model)) +
  theme_bw() + theme(legend.position = "none")
```





