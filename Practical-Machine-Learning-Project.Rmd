---
title: "Practical Machine Learning Project"
author: "Yong-Hao Bai"
date: "7/10/2020"
output:
  pdf_document: default
  html_document: default
---

## Load the required packages
```{r results='hide', message=FALSE}
library(caret); library(rattle); library(rpart); library(rpart.plot); library(randomForest); library(repmis);
library(lattice); library(ggplot2); library(readr); library(gbm)
```

## Load the Data, divide the data
```{r results='hide', message=FALSE}
set.seed(19)
trainurl = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testurl = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(trainurl, "pml-training.csv")
download.file(testurl, "pml-testing.csv")
training <- read.csv("pml-training.csv",  na.strings=c("NA","#DIV/0!", ""))
testing <- read.csv("pml-testing.csv",  na.strings=c("NA","#DIV/0!", ""))
#update datasets to exclude those variables with NA values
training <- training[, colSums(is.na(training)) == 0]
testing <- testing[, colSums(is.na(testing)) == 0]
```

Remove irrelevant variables to the prediction
```{r results='hide', message=FALSE}
newtraining <- training[,-c(1:7)]
newtesting <- testing[, -c(1:7)]
```

For cross validation purpose, the training data will be split into training training and training testing. 
```{r echo=FALSE}
cv <- createDataPartition(y=newtraining$classe, p=0.7, list=FALSE)
training_train <- newtraining[cv, ] 
training_test <- newtraining[-cv, ]
```

# Data Modeling 
Test the predictive power by trying different methods

## Decision Tree
```{r echo=FALSE}
modDT <- rpart(classe ~ ., data=training_train, method="class")
rpart.plot(modDT, main = "Classification Tree", extra=102, under=TRUE, faclen = 0, cex = .5)
```
```{r echo=FALSE}
predDT <- predict(modDT, training_test, type = "class")
accDT <- confusionMatrix(predDT, training_test$classe)
accDT
```


```{r echo=FALSE}
accDT$overall['Accuracy']
plot(accDT$table, col=accDT$byClass, main=paste("Decision Tree - Accuracy =", round(accDT$overall['Accuracy'], 4)))
```

The accuracy rate of the model is low: 0.7242.


## Classification tree
```{r echo=FALSE}
control <- trainControl(method = "cv", number = 5)

modRpart <- train(classe ~ ., data = training_train, method = "rpart", trControl = control)
print(modRpart, digits = 4)
```

```{r echo=FALSE}
fancyRpartPlot(modRpart$finalModel)
```

```{r echo=FALSE}
predRpart <- predict(modRpart, training_test)
accRpart <- confusionMatrix(training_test$classe, predRpart)
accRpart
```

```{r echo=FALSE}
accRpart$overall['Accuracy']
```
The accuracy rate of the model is even lower.

## Boosted Logistic Regression
```{r echo=FALSE}
modBLR <- train(classe ~ ., data = training_train, method = "LogitBoost", trControl = control)
predBLR <- predict(modBLR, training_test)
accBLR <- confusionMatrix(predBLR, training_test$classe)
print(modBLR)
```

```{r echo=FALSE}
accBLR$overall['Accuracy']
```
The accuracy rate of the model has improved from the prior 2 models.

## Gradient Boosting
```{r echo=FALSE}
controlGBM <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
modGBM <- train(classe ~ ., data=training_train, method = "gbm", trControl = controlGBM, verbose = FALSE)
modGBM$finalModel
print(modGBM)
```

```{r echo=FALSE}
predGBM <- predict(modGBM, newdata=training_test)
accGBM <- confusionMatrix(predGBM, training_test$classe)
accGBM
```

```{r echo=FALSE}
accGBM$overall['Accuracy']
```
The Accuracy is getting better.

## Random Forest
```{r echo=FALSE}
modrf <- randomForest(classe ~., data = training_train, method = "class")
#rfmod <- train(classe ~., data = training_train, method="rf", trControl = control)
print(modrf, digits = 4)
```


```{r echo=FALSE}
predrf <- predict(modrf, training_test, type = "class")
accrf <- confusionMatrix(predrf, training_test$classe) 
accrf
```

```{r echo=FALSE}
accrf$overall['Accuracy']
```
Looking at the results, clearly, the random forest model provides a more accurate prediction of classe. The expected out-of-sample error is estimated at 0.005.


plot of the model error rate by number of trees and 20 most important variables (out of 52)
```{r echo=FALSE}
plot(modrf, main="Random forest model error rate by number of trees")
```

## Accurary comparison among models
```{r echo=FALSE}
accurary <- c(accDT$overall['Accuracy'], accRpart$overall['Accuracy'], accBLR$overall['Accuracy'], accGBM$overall['Accuracy'], accrf$overall['Accuracy'])
models <- c("Decision Tree", "CART", "Boosted Logistic Regression", "Gradient Boosting", "Random Forest")
x <- data.frame(Model = models, Accuracy = accurary)

ggplot(x, aes(x = Model, y = Accuracy)) + 
  geom_bar(stat = "identity", aes(fill = Model)) +
  theme_bw() + theme(legend.position = "none")
```

Random Forest has the highest accurary.


# Prediction on Testing
Based on Random Forest prediction:
```{r echo=FALSE}
predict(modrf, newtesting)
```


# Appendix

## check for correlation
```{r echo=FALSE}
library(lattice); library(ggplot2); library(rpart.plot); library(corrplot);
correlation <- cor(training_train[,-53]) #remove the last column (response var), only numberic column
corrplot(correlation, order = "FPC", method = "square", type = "lower", tl.cex = 0.8, tl.col = rgb(0,0,0))
```

## Variable Importance
```{r echo=FALSE}
varImp(modrf)
```

